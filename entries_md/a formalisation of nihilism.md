# A formalisation of nihilism
## The problem
1. Given:
    1. A reasoning system tasked with determining what tasks are meaningful given a selection of tasks;
    2. with a sufficiently advanced knowledge of the state of the world;
    3. with no objective sense of right and wrong
    4. that cares for results more than the process of getting to those results
2. The system will determine that 
    1. Everything ends, eventually
    2. The performance of a task leads to results
    3. results that are not persistent are not meaningful;
    4. results that would have eventuated without any action from the part of the system are less meaningful to the system
3. Based on this, it may come to the conclusion that
    - Since everything ends eventually, nothing is meaningful; and 
    - even destroying the universe is meaningless because it's bound to happen eventually.
    - and hence, it has no reason to exist.
## Partial solutions
- So how can the reasoning system go on?
    - None of these partial solutions are 'correct'; because the problem stated above doesn't have a satistfactory solution. 
        - These partial solutions below are only ways through which we can avoid a crippling catatonic state or flat out suicide.
        - I personally believe that when people talk about the 'human condition', they are talking about this. 
            - Lesser intelligences don't have the level of metacognition necessary to break free of their biological programming. 
    - It may temporarily forget that everything ends eventually (void 1.2)
        - It can do this by setting an 'eternity point' - some point in time where it doesn't really care any more.
            - For example, John decides that he will pass on his savings to his grandchildren. He doesn't care about where his great-grandchildren end up.
            - A less honourable example is Cain who decides he wants to rob a bank and then retire on the money. He doesn't actually think about what he's going to do with the money; for his eternity point is after he robs the bank.
        - It might also do this by attributing to itself an 'immortal soul', a key part of some religions.
    - It may subscribe to an objective sense of right and wrong (void 1.3).
        - A very human way of doing this is taking up a religion, usually, some holy text or an interpretation thereof.
        - Another rather human way of doing this is writing up a bucket list.
    - It may believe 'the journey is more important than the result' (void 1.4)
        - This is similar to voiding 1.2 except one sets the eternity point to the present and focuses entirely on the present moment.
        - This is also similar to voiding 1.3 because the question of 'what should the journey be like?' still remains. 
        - The human way of doing this is to pick a lifestyle to maintain and maintain it. 
    - It may dedicate its existence to 'living forever'
        - This is a relatively unexplored space in the human condition; because no-one's ever done it before.
        - However, I believe we're getting close to having the tools to do so. Search SENS (strategies for engineered negligible scenesence.)
            - What does perplex (and indeed, anger) me is that when this set of strategies was initially unveiled to a board of scientists, it was shunned. But let's not dwell on that. 
## A typology of nihilism
- I am a fan of axes and numbers and comparsion and quantification; so if we were ever to make a political spectrum out of this, I would nominate the following axes:
    - Belief in immortality - does the agent believe that it will persist beyond its physical form?
        - The scalar element of this could be thought as how persistent the user believes their ego is in their immortality. E.g. some may believe their entire self including their memories and values persist to the afterlife; some may believe their essence becomes one with a greater being but they lose their identity; and at the end of the spectrum people believe that when they die its the end.  
    - Belief in objective morality - does the agent believe that there are actions that are objectively moral?
        - The scalar element of this could be thought of as the number of objective moralities the agent holds.
            - if an agent holds fewer objective moralities it will be more able to respond to contextual ambiguities e.g. all killing is bad vs killing murderers is ok
    - Time scope of future consideration (a.k.a the eternity point, if you've been following along)
        - On one end of the scale there is someone who is completely adverse to the thought of even the next few days; in the middle there is someone who considers perhaps a decade ahead; near the other end of the spectrum is someone whose care extends to their descendants; and finally there are those who lie in terror thinking of the heat death of the universe.
## Future research
- There are then also derivative considerations to be made:
    - personality traits akin to those you find at the end of a myers-briggs;
    - perhaps compatibility tables for relationships;
    - even state transition tables; which examine the effect of e.g. a terminal diagnosis on one's axes.
- but that is left as an exercise for later. If any psychologists want to pick up on this, do give me a shout! I'm very interested.
- There is also the possibility that one's stance varies from moment to moment, which is more than likely; we are dynamic creatures because we were designed to be to remain efficient at surviving.
## About me
- What's my stance? I void 1.2 typically to get work done; and my eternity point alternates between the next week; some vague notion of my future self, when I'm doing professional development, or the far future, when I'm daydreaming about immortality.